#!/bin/bash
#SBATCH --job-name=coco_slak_tiny_120_scalelr_1x
#SBATCH -p gpu
#SBATCH -N 1
#SBATCH --ntasks-per-node=1
#SBATCH --gpus-per-node=4
#SBATCH --gpus=4
#SBATCH -t 3-12:00:00
#SBATCH --exclusive
#SBATCH --cpus-per-task=72
#SBATCH -o coco_slak_tiny_120_scalelr_1x.out

source /home/sliu/miniconda3/etc/profile.d/conda.sh
source activate slak

#module purge
#module load 2021
#module load CUDA/11.3.1
#module load PyTorch/1.10.0-foss-2021a-CUDA-11.3.1


python -m torch.distributed.launch --nproc_per_node=4 tools/train.py configs/SLaK/cascade_mask_rcnn_slak_tiny_120_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco_in1k.py \
--launcher pytorch --options model.backbone.pretrained=~/project_space/LoRA_LK/transfer/convnext_tiny_Rep/51494713/W_S_ana/w1.3_s0.6_snip_100_pr0.3/120epochs_random/checkpoint-best.pth \
--work-dir /projects/0/prjste21060/projects/Detection/Coco_slak_tiny_120epochs_fix_scalelr_1x/  --auto-resume --auto-scale-lr

source deactivate
